Skip to content

[ ![logo](../../../img/logo-white.svg) ](../../.. "PydanticAI")

PydanticAI

pydantic_ai.models

Type to start searching

[ pydantic/pydantic-ai

  * v0.0.50
  * 8k
  * 687

](https://github.com/pydantic/pydantic-ai "Go to repository")

[ ![logo](../../../img/logo-white.svg) ](../../.. "PydanticAI") PydanticAI

[ pydantic/pydantic-ai

  * v0.0.50
  * 8k
  * 687

](https://github.com/pydantic/pydantic-ai "Go to repository")

  * [ Introduction  ](../../..)
  * [ Installation  ](../../../install/)
  * [ Getting Help  ](../../../help/)
  * [ Contributing  ](../../../contributing/)
  * [ Troubleshooting  ](../../../troubleshooting/)
  * Documentation  Documentation 
    * [ Agents  ](../../../agents/)
    * [ Models  ](../../../models/)
    * [ Dependencies  ](../../../dependencies/)
    * [ Function Tools  ](../../../tools/)
    * [ Common Tools  ](../../../common-tools/)
    * [ Results  ](../../../results/)
    * [ Messages and chat history  ](../../../message-history/)
    * [ Unit testing  ](../../../testing/)
    * [ Debugging and Monitoring  ](../../../logfire/)
    * [ Multi-agent Applications  ](../../../multi-agent-applications/)
    * [ Graphs  ](../../../graph/)
    * [ Evals  ](../../../evals/)
    * [ Image, Audio & Document Input  ](../../../input/)
    * [ MCP  ](../../../mcp/)

MCP

      * [ Client  ](../../../mcp/client/)
      * [ Server  ](../../../mcp/server/)
      * [ MCP Run Python  ](../../../mcp/run-python/)
    * [ Command Line Interface (CLI)  ](../../../cli/)
  * [ Examples  ](../../../examples/)

Examples

    * [ Pydantic Model  ](../../../examples/pydantic-model/)
    * [ Weather agent  ](../../../examples/weather-agent/)
    * [ Bank support  ](../../../examples/bank-support/)
    * [ SQL Generation  ](../../../examples/sql-gen/)
    * [ Flight booking  ](../../../examples/flight-booking/)
    * [ RAG  ](../../../examples/rag/)
    * [ Stream markdown  ](../../../examples/stream-markdown/)
    * [ Stream whales  ](../../../examples/stream-whales/)
    * [ Chat App with FastAPI  ](../../../examples/chat-app/)
    * [ Question Graph  ](../../../examples/question-graph/)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](../../agent/)
    * [ pydantic_ai.tools  ](../../tools/)
    * [ pydantic_ai.common_tools  ](../../common_tools/)
    * [ pydantic_ai.result  ](../../result/)
    * [ pydantic_ai.messages  ](../../messages/)
    * [ pydantic_ai.exceptions  ](../../exceptions/)
    * [ pydantic_ai.settings  ](../../settings/)
    * [ pydantic_ai.usage  ](../../usage/)
    * [ pydantic_ai.mcp  ](../../mcp/)
    * [ pydantic_ai.format_as_xml  ](../../format_as_xml/)
    * pydantic_ai.models  [ pydantic_ai.models  ](./) Table of contents 
      * models 
      * KnownModelName 
      * ModelRequestParameters 
      * Model 
        * request 
        * request_stream 
        * model_name 
        * system 
        * base_url 
      * StreamedResponse 
        * __aiter__ 
        * get 
        * usage 
        * model_name 
        * timestamp 
      * ALLOW_MODEL_REQUESTS 
      * check_allow_model_requests 
      * override_allow_model_requests 
    * [ pydantic_ai.models.openai  ](../openai/)
    * [ pydantic_ai.models.anthropic  ](../anthropic/)
    * [ pydantic_ai.models.bedrock  ](../bedrock/)
    * [ pydantic_ai.models.cohere  ](../cohere/)
    * [ pydantic_ai.models.gemini  ](../gemini/)
    * [ pydantic_ai.models.groq  ](../groq/)
    * [ pydantic_ai.models.instrumented  ](../instrumented/)
    * [ pydantic_ai.models.mistral  ](../mistral/)
    * [ pydantic_ai.models.test  ](../test/)
    * [ pydantic_ai.models.function  ](../function/)
    * [ pydantic_ai.models.fallback  ](../fallback/)
    * [ pydantic_ai.models.wrapper  ](../wrapper/)
    * [ pydantic_ai.providers  ](../../providers/)
    * [ pydantic_graph  ](../../pydantic_graph/graph/)
    * [ pydantic_graph.nodes  ](../../pydantic_graph/nodes/)
    * [ pydantic_graph.persistence  ](../../pydantic_graph/persistence/)
    * [ pydantic_graph.mermaid  ](../../pydantic_graph/mermaid/)
    * [ pydantic_graph.exceptions  ](../../pydantic_graph/exceptions/)
    * [ pydantic_evals.dataset  ](../../pydantic_evals/dataset/)
    * [ pydantic_evals.evaluators  ](../../pydantic_evals/evaluators/)
    * [ pydantic_evals.reporting  ](../../pydantic_evals/reporting/)
    * [ pydantic_evals.otel  ](../../pydantic_evals/otel/)
    * [ pydantic_evals.generation  ](../../pydantic_evals/generation/)

Table of contents

  * models 
  * KnownModelName 
  * ModelRequestParameters 
  * Model 
    * request 
    * request_stream 
    * model_name 
    * system 
    * base_url 
  * StreamedResponse 
    * __aiter__ 
    * get 
    * usage 
    * model_name 
    * timestamp 
  * ALLOW_MODEL_REQUESTS 
  * check_allow_model_requests 
  * override_allow_model_requests 

# `pydantic_ai.models`

Logic related to making requests to an LLM.

The aim here is to make a common interface for different LLMs, so that the
rest of the code can be agnostic to the specific LLM being used.

###  KnownModelName `module-attribute`

    
    
    KnownModelName = [TypeAliasType](https://typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypeAliasType "typing_extensions.TypeAliasType")(
        "KnownModelName",
        [Literal](https://typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Literal "typing_extensions.Literal")[
            "anthropic:claude-3-7-sonnet-latest",
            "anthropic:claude-3-5-haiku-latest",
            "anthropic:claude-3-5-sonnet-latest",
            "anthropic:claude-3-opus-latest",
            "claude-3-7-sonnet-latest",
            "claude-3-5-haiku-latest",
            "bedrock:amazon.titan-tg1-large",
            "bedrock:amazon.titan-text-lite-v1",
            "bedrock:amazon.titan-text-express-v1",
            "bedrock:us.amazon.nova-pro-v1:0",
            "bedrock:us.amazon.nova-lite-v1:0",
            "bedrock:us.amazon.nova-micro-v1:0",
            "bedrock:anthropic.claude-3-5-sonnet-20241022-v2:0",
            "bedrock:us.anthropic.claude-3-5-sonnet-20241022-v2:0",
            "bedrock:anthropic.claude-3-5-haiku-20241022-v1:0",
            "bedrock:us.anthropic.claude-3-5-haiku-20241022-v1:0",
            "bedrock:anthropic.claude-instant-v1",
            "bedrock:anthropic.claude-v2:1",
            "bedrock:anthropic.claude-v2",
            "bedrock:anthropic.claude-3-sonnet-20240229-v1:0",
            "bedrock:us.anthropic.claude-3-sonnet-20240229-v1:0",
            "bedrock:anthropic.claude-3-haiku-20240307-v1:0",
            "bedrock:us.anthropic.claude-3-haiku-20240307-v1:0",
            "bedrock:anthropic.claude-3-opus-20240229-v1:0",
            "bedrock:us.anthropic.claude-3-opus-20240229-v1:0",
            "bedrock:anthropic.claude-3-5-sonnet-20240620-v1:0",
            "bedrock:us.anthropic.claude-3-5-sonnet-20240620-v1:0",
            "bedrock:anthropic.claude-3-7-sonnet-20250219-v1:0",
            "bedrock:us.anthropic.claude-3-7-sonnet-20250219-v1:0",
            "bedrock:cohere.command-text-v14",
            "bedrock:cohere.command-r-v1:0",
            "bedrock:cohere.command-r-plus-v1:0",
            "bedrock:cohere.command-light-text-v14",
            "bedrock:meta.llama3-8b-instruct-v1:0",
            "bedrock:meta.llama3-70b-instruct-v1:0",
            "bedrock:meta.llama3-1-8b-instruct-v1:0",
            "bedrock:us.meta.llama3-1-8b-instruct-v1:0",
            "bedrock:meta.llama3-1-70b-instruct-v1:0",
            "bedrock:us.meta.llama3-1-70b-instruct-v1:0",
            "bedrock:meta.llama3-1-405b-instruct-v1:0",
            "bedrock:us.meta.llama3-2-11b-instruct-v1:0",
            "bedrock:us.meta.llama3-2-90b-instruct-v1:0",
            "bedrock:us.meta.llama3-2-1b-instruct-v1:0",
            "bedrock:us.meta.llama3-2-3b-instruct-v1:0",
            "bedrock:us.meta.llama3-3-70b-instruct-v1:0",
            "bedrock:mistral.mistral-7b-instruct-v0:2",
            "bedrock:mistral.mixtral-8x7b-instruct-v0:1",
            "bedrock:mistral.mistral-large-2402-v1:0",
            "bedrock:mistral.mistral-large-2407-v1:0",
            "claude-3-5-sonnet-latest",
            "claude-3-opus-latest",
            "cohere:c4ai-aya-expanse-32b",
            "cohere:c4ai-aya-expanse-8b",
            "cohere:command",
            "cohere:command-light",
            "cohere:command-light-nightly",
            "cohere:command-nightly",
            "cohere:command-r",
            "cohere:command-r-03-2024",
            "cohere:command-r-08-2024",
            "cohere:command-r-plus",
            "cohere:command-r-plus-04-2024",
            "cohere:command-r-plus-08-2024",
            "cohere:command-r7b-12-2024",
            "deepseek:deepseek-chat",
            "deepseek:deepseek-reasoner",
            "google-gla:gemini-1.0-pro",
            "google-gla:gemini-1.5-flash",
            "google-gla:gemini-1.5-flash-8b",
            "google-gla:gemini-1.5-pro",
            "google-gla:gemini-2.0-flash-exp",
            "google-gla:gemini-2.0-flash-thinking-exp-01-21",
            "google-gla:gemini-exp-1206",
            "google-gla:gemini-2.0-flash",
            "google-gla:gemini-2.0-flash-lite-preview-02-05",
            "google-gla:gemini-2.0-pro-exp-02-05",
            "google-gla:gemini-2.5-pro-exp-03-25",
            "google-vertex:gemini-1.0-pro",
            "google-vertex:gemini-1.5-flash",
            "google-vertex:gemini-1.5-flash-8b",
            "google-vertex:gemini-1.5-pro",
            "google-vertex:gemini-2.0-flash-exp",
            "google-vertex:gemini-2.0-flash-thinking-exp-01-21",
            "google-vertex:gemini-exp-1206",
            "google-vertex:gemini-2.0-flash",
            "google-vertex:gemini-2.0-flash-lite-preview-02-05",
            "google-vertex:gemini-2.0-pro-exp-02-05",
            "google-vertex:gemini-2.5-pro-exp-03-25",
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-0125",
            "gpt-3.5-turbo-0301",
            "gpt-3.5-turbo-0613",
            "gpt-3.5-turbo-1106",
            "gpt-3.5-turbo-16k",
            "gpt-3.5-turbo-16k-0613",
            "gpt-4",
            "gpt-4-0125-preview",
            "gpt-4-0314",
            "gpt-4-0613",
            "gpt-4-1106-preview",
            "gpt-4-32k",
            "gpt-4-32k-0314",
            "gpt-4-32k-0613",
            "gpt-4-turbo",
            "gpt-4-turbo-2024-04-09",
            "gpt-4-turbo-preview",
            "gpt-4-vision-preview",
            "gpt-4o",
            "gpt-4o-2024-05-13",
            "gpt-4o-2024-08-06",
            "gpt-4o-2024-11-20",
            "gpt-4o-audio-preview",
            "gpt-4o-audio-preview-2024-10-01",
            "gpt-4o-audio-preview-2024-12-17",
            "gpt-4o-mini",
            "gpt-4o-mini-2024-07-18",
            "gpt-4o-mini-audio-preview",
            "gpt-4o-mini-audio-preview-2024-12-17",
            "gpt-4o-mini-search-preview",
            "gpt-4o-mini-search-preview-2025-03-11",
            "gpt-4o-search-preview",
            "gpt-4o-search-preview-2025-03-11",
            "groq:distil-whisper-large-v3-en",
            "groq:gemma2-9b-it",
            "groq:llama-3.3-70b-versatile",
            "groq:llama-3.1-8b-instant",
            "groq:llama-guard-3-8b",
            "groq:llama3-70b-8192",
            "groq:llama3-8b-8192",
            "groq:whisper-large-v3",
            "groq:whisper-large-v3-turbo",
            "groq:playai-tts",
            "groq:playai-tts-arabic",
            "groq:qwen-qwq-32b",
            "groq:mistral-saba-24b",
            "groq:qwen-2.5-coder-32b",
            "groq:qwen-2.5-32b",
            "groq:deepseek-r1-distill-qwen-32b",
            "groq:deepseek-r1-distill-llama-70b",
            "groq:llama-3.3-70b-specdec",
            "groq:llama-3.2-1b-preview",
            "groq:llama-3.2-3b-preview",
            "groq:llama-3.2-11b-vision-preview",
            "groq:llama-3.2-90b-vision-preview",
            "mistral:codestral-latest",
            "mistral:mistral-large-latest",
            "mistral:mistral-moderation-latest",
            "mistral:mistral-small-latest",
            "o1",
            "o1-2024-12-17",
            "o1-mini",
            "o1-mini-2024-09-12",
            "o1-preview",
            "o1-preview-2024-09-12",
            "o3-mini",
            "o3-mini-2025-01-31",
            "openai:chatgpt-4o-latest",
            "openai:gpt-3.5-turbo",
            "openai:gpt-3.5-turbo-0125",
            "openai:gpt-3.5-turbo-0301",
            "openai:gpt-3.5-turbo-0613",
            "openai:gpt-3.5-turbo-1106",
            "openai:gpt-3.5-turbo-16k",
            "openai:gpt-3.5-turbo-16k-0613",
            "openai:gpt-4",
            "openai:gpt-4-0125-preview",
            "openai:gpt-4-0314",
            "openai:gpt-4-0613",
            "openai:gpt-4-1106-preview",
            "openai:gpt-4-32k",
            "openai:gpt-4-32k-0314",
            "openai:gpt-4-32k-0613",
            "openai:gpt-4-turbo",
            "openai:gpt-4-turbo-2024-04-09",
            "openai:gpt-4-turbo-preview",
            "openai:gpt-4-vision-preview",
            "openai:gpt-4o",
            "openai:gpt-4o-2024-05-13",
            "openai:gpt-4o-2024-08-06",
            "openai:gpt-4o-2024-11-20",
            "openai:gpt-4o-audio-preview",
            "openai:gpt-4o-audio-preview-2024-10-01",
            "openai:gpt-4o-audio-preview-2024-12-17",
            "openai:gpt-4o-mini",
            "openai:gpt-4o-mini-2024-07-18",
            "openai:gpt-4o-mini-audio-preview",
            "openai:gpt-4o-mini-audio-preview-2024-12-17",
            "openai:gpt-4o-mini-search-preview",
            "openai:gpt-4o-mini-search-preview-2025-03-11",
            "openai:gpt-4o-search-preview",
            "openai:gpt-4o-search-preview-2025-03-11",
            "openai:o1",
            "openai:o1-2024-12-17",
            "openai:o1-mini",
            "openai:o1-mini-2024-09-12",
            "openai:o1-preview",
            "openai:o1-preview-2024-09-12",
            "openai:o3-mini",
            "openai:o3-mini-2025-01-31",
            "test",
        ],
    )
    

Known model names that can be used with the `model` parameter of
[`Agent`](../../agent/#pydantic_ai.agent.Agent).

`KnownModelName` is provided as a concise way to specify a model.

###  ModelRequestParameters `dataclass`

Configuration for an agent's request to a model, specifically related to tools
and result handling.

Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    241
    242
    243
    244
    245
    246
    247

|

    
    
    @dataclass
    class ModelRequestParameters:
        """Configuration for an agent's request to a model, specifically related to tools and result handling."""
    
        function_tools: list[ToolDefinition]
        allow_text_result: bool
        result_tools: list[ToolDefinition]
      
  
---|---  
  
###  Model

Bases: `[ABC](https://docs.python.org/3/library/abc.html#abc.ABC "abc.ABC")`

Abstract class for a model.

Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    250
    251
    252
    253
    254
    255
    256
    257
    258
    259
    260
    261
    262
    263
    264
    265
    266
    267
    268
    269
    270
    271
    272
    273
    274
    275
    276
    277
    278
    279
    280
    281
    282
    283
    284
    285
    286
    287
    288
    289
    290
    291
    292
    293
    294
    295
    296
    297
    298

|

    
    
    class Model(ABC):
        """Abstract class for a model."""
    
        @abstractmethod
        async def request(
            self,
            messages: list[ModelMessage],
            model_settings: ModelSettings | None,
            model_request_parameters: ModelRequestParameters,
        ) -> tuple[ModelResponse, Usage]:
            """Make a request to the model."""
            raise NotImplementedError()
    
        @asynccontextmanager
        async def request_stream(
            self,
            messages: list[ModelMessage],
            model_settings: ModelSettings | None,
            model_request_parameters: ModelRequestParameters,
        ) -> AsyncIterator[StreamedResponse]:
            """Make a request to the model and return a streaming response."""
            # This method is not required, but you need to implement it if you want to support streamed responses
            raise NotImplementedError(f'Streamed requests not supported by this {self.__class__.__name__}')
            # yield is required to make this a generator for type checking
            # noinspection PyUnreachableCode
            yield  # pragma: no cover
    
        @property
        @abstractmethod
        def model_name(self) -> str:
            """The model name."""
            raise NotImplementedError()
    
        @property
        @abstractmethod
        def system(self) -> str:
            """The system / model provider, ex: openai.
    
            Use to populate the `gen_ai.system` OpenTelemetry semantic convention attribute,
            so should use well-known values listed in
            https://opentelemetry.io/docs/specs/semconv/attributes-registry/gen-ai/#gen-ai-system
            when applicable.
            """
            raise NotImplementedError()
    
        @property
        def base_url(self) -> str | None:
            """The base URL for the provider API, if available."""
            return None
      
  
---|---  
  
####  request `abstractmethod` `async`

    
    
    request(
        messages: [list](https://docs.python.org/3/library/stdtypes.html#list)[[ModelMessage](../../messages/#pydantic_ai.messages.ModelMessage "pydantic_ai.messages.ModelMessage")],
        model_settings: [ModelSettings](../../settings/#pydantic_ai.settings.ModelSettings "pydantic_ai.settings.ModelSettings") | None,
        model_request_parameters: ModelRequestParameters,
    ) -> [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)[[ModelResponse](../../messages/#pydantic_ai.messages.ModelResponse "pydantic_ai.messages.ModelResponse"), [Usage](../../usage/#pydantic_ai.usage.Usage "pydantic_ai.usage.Usage")]
    

Make a request to the model.

Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    253
    254
    255
    256
    257
    258
    259
    260
    261

|

    
    
    @abstractmethod
    async def request(
        self,
        messages: list[ModelMessage],
        model_settings: ModelSettings | None,
        model_request_parameters: ModelRequestParameters,
    ) -> tuple[ModelResponse, Usage]:
        """Make a request to the model."""
        raise NotImplementedError()
      
  
---|---  
  
####  request_stream `async`

    
    
    request_stream(
        messages: [list](https://docs.python.org/3/library/stdtypes.html#list)[[ModelMessage](../../messages/#pydantic_ai.messages.ModelMessage "pydantic_ai.messages.ModelMessage")],
        model_settings: [ModelSettings](../../settings/#pydantic_ai.settings.ModelSettings "pydantic_ai.settings.ModelSettings") | None,
        model_request_parameters: ModelRequestParameters,
    ) -> [AsyncIterator](https://docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator "collections.abc.AsyncIterator")[StreamedResponse]
    

Make a request to the model and return a streaming response.

Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    263
    264
    265
    266
    267
    268
    269
    270
    271
    272
    273
    274
    275

|

    
    
    @asynccontextmanager
    async def request_stream(
        self,
        messages: list[ModelMessage],
        model_settings: ModelSettings | None,
        model_request_parameters: ModelRequestParameters,
    ) -> AsyncIterator[StreamedResponse]:
        """Make a request to the model and return a streaming response."""
        # This method is not required, but you need to implement it if you want to support streamed responses
        raise NotImplementedError(f'Streamed requests not supported by this {self.__class__.__name__}')
        # yield is required to make this a generator for type checking
        # noinspection PyUnreachableCode
        yield  # pragma: no cover
      
  
---|---  
  
####  model_name `abstractmethod` `property`

    
    
    model_name: [str](https://docs.python.org/3/library/stdtypes.html#str)
    

The model name.

####  system `abstractmethod` `property`

    
    
    system: [str](https://docs.python.org/3/library/stdtypes.html#str)
    

The system / model provider, ex: openai.

Use to populate the `gen_ai.system` OpenTelemetry semantic convention
attribute, so should use well-known values listed in
https://opentelemetry.io/docs/specs/semconv/attributes-registry/gen-ai/#gen-
ai-system when applicable.

####  base_url `property`

    
    
    base_url: [str](https://docs.python.org/3/library/stdtypes.html#str) | None
    

The base URL for the provider API, if available.

###  StreamedResponse `dataclass`

Bases: `[ABC](https://docs.python.org/3/library/abc.html#abc.ABC "abc.ABC")`

Streamed response from an LLM when calling a tool.

Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    301
    302
    303
    304
    305
    306
    307
    308
    309
    310
    311
    312
    313
    314
    315
    316
    317
    318
    319
    320
    321
    322
    323
    324
    325
    326
    327
    328
    329
    330
    331
    332
    333
    334
    335
    336
    337
    338
    339
    340
    341
    342
    343
    344
    345
    346
    347
    348

|

    
    
    @dataclass
    class StreamedResponse(ABC):
        """Streamed response from an LLM when calling a tool."""
    
        _parts_manager: ModelResponsePartsManager = field(default_factory=ModelResponsePartsManager, init=False)
        _event_iterator: AsyncIterator[ModelResponseStreamEvent] | None = field(default=None, init=False)
        _usage: Usage = field(default_factory=Usage, init=False)
    
        def __aiter__(self) -> AsyncIterator[ModelResponseStreamEvent]:
            """Stream the response as an async iterable of [`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s."""
            if self._event_iterator is None:
                self._event_iterator = self._get_event_iterator()
            return self._event_iterator
    
        @abstractmethod
        async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
            """Return an async iterator of [`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s.
    
            This method should be implemented by subclasses to translate the vendor-specific stream of events into
            pydantic_ai-format events.
    
            It should use the `_parts_manager` to handle deltas, and should update the `_usage` attributes as it goes.
            """
            raise NotImplementedError()
            # noinspection PyUnreachableCode
            yield
    
        def get(self) -> ModelResponse:
            """Build a [`ModelResponse`][pydantic_ai.messages.ModelResponse] from the data received from the stream so far."""
            return ModelResponse(
                parts=self._parts_manager.get_parts(), model_name=self.model_name, timestamp=self.timestamp
            )
    
        def usage(self) -> Usage:
            """Get the usage of the response so far. This will not be the final usage until the stream is exhausted."""
            return self._usage
    
        @property
        @abstractmethod
        def model_name(self) -> str:
            """Get the model name of the response."""
            raise NotImplementedError()
    
        @property
        @abstractmethod
        def timestamp(self) -> datetime:
            """Get the timestamp of the response."""
            raise NotImplementedError()
      
  
---|---  
  
####  __aiter__

    
    
    __aiter__() -> [AsyncIterator](https://docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator "collections.abc.AsyncIterator")[[ModelResponseStreamEvent](../../messages/#pydantic_ai.messages.ModelResponseStreamEvent "pydantic_ai.messages.ModelResponseStreamEvent")]
    

Stream the response as an async iterable of
[`ModelResponseStreamEvent`](../../messages/#pydantic_ai.messages.ModelResponseStreamEvent)s.

Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    309
    310
    311
    312
    313

|

    
    
    def __aiter__(self) -> AsyncIterator[ModelResponseStreamEvent]:
        """Stream the response as an async iterable of [`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s."""
        if self._event_iterator is None:
            self._event_iterator = self._get_event_iterator()
        return self._event_iterator
      
  
---|---  
  
####  get

    
    
    get() -> [ModelResponse](../../messages/#pydantic_ai.messages.ModelResponse "pydantic_ai.messages.ModelResponse")
    

Build a [`ModelResponse`](../../messages/#pydantic_ai.messages.ModelResponse)
from the data received from the stream so far.

Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    328
    329
    330
    331
    332

|

    
    
    def get(self) -> ModelResponse:
        """Build a [`ModelResponse`][pydantic_ai.messages.ModelResponse] from the data received from the stream so far."""
        return ModelResponse(
            parts=self._parts_manager.get_parts(), model_name=self.model_name, timestamp=self.timestamp
        )
      
  
---|---  
  
####  usage

    
    
    usage() -> [Usage](../../usage/#pydantic_ai.usage.Usage "pydantic_ai.usage.Usage")
    

Get the usage of the response so far. This will not be the final usage until
the stream is exhausted.

Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    334
    335
    336

|

    
    
    def usage(self) -> Usage:
        """Get the usage of the response so far. This will not be the final usage until the stream is exhausted."""
        return self._usage
      
  
---|---  
  
####  model_name `abstractmethod` `property`

    
    
    model_name: [str](https://docs.python.org/3/library/stdtypes.html#str)
    

Get the model name of the response.

####  timestamp `abstractmethod` `property`

    
    
    timestamp: [datetime](https://docs.python.org/3/library/datetime.html#datetime.datetime "datetime.datetime")
    

Get the timestamp of the response.

###  ALLOW_MODEL_REQUESTS `module-attribute`

    
    
    ALLOW_MODEL_REQUESTS = True
    

Whether to allow requests to models.

This global setting allows you to disable request to most models, e.g. to make
sure you don't accidentally make costly requests to a model during tests.

The testing models [`TestModel`](../test/#pydantic_ai.models.test.TestModel)
and [`FunctionModel`](../function/#pydantic_ai.models.function.FunctionModel)
are no affected by this setting.

###  check_allow_model_requests

    
    
    check_allow_model_requests() -> None
    

Check if model requests are allowed.

If you're defining your own models that have costs or latency associated with
their use, you should call this in `Model.request` and `Model.request_stream`.

Raises:

Type | Description  
---|---  
`[RuntimeError](https://docs.python.org/3/library/exceptions.html#RuntimeError)` |  If model requests are not allowed.  
  
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    362
    363
    364
    365
    366
    367
    368
    369
    370
    371
    372

|

    
    
    def check_allow_model_requests() -> None:
        """Check if model requests are allowed.
    
        If you're defining your own models that have costs or latency associated with their use, you should call this in
        [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].
    
        Raises:
            RuntimeError: If model requests are not allowed.
        """
        if not ALLOW_MODEL_REQUESTS:
            raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')
      
  
---|---  
  
###  override_allow_model_requests

    
    
    override_allow_model_requests(
        allow_model_requests: [bool](https://docs.python.org/3/library/functions.html#bool),
    ) -> [Iterator](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterator "collections.abc.Iterator")[None]
    

Context manager to temporarily override `ALLOW_MODEL_REQUESTS`.

Parameters:

Name | Type | Description | Default  
---|---|---|---  
`allow_model_requests` |  `[bool](https://docs.python.org/3/library/functions.html#bool)` |  Whether to allow model requests within the context. |  _required_  
  
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`

    
    
    375
    376
    377
    378
    379
    380
    381
    382
    383
    384
    385
    386
    387
    388

|

    
    
    @contextmanager
    def override_allow_model_requests(allow_model_requests: bool) -> Iterator[None]:
        """Context manager to temporarily override [`ALLOW_MODEL_REQUESTS`][pydantic_ai.models.ALLOW_MODEL_REQUESTS].
    
        Args:
            allow_model_requests: Whether to allow model requests within the context.
        """
        global ALLOW_MODEL_REQUESTS
        old_value = ALLOW_MODEL_REQUESTS
        ALLOW_MODEL_REQUESTS = allow_model_requests  # pyright: ignore[reportConstantRedefinition]
        try:
            yield
        finally:
            ALLOW_MODEL_REQUESTS = old_value  # pyright: ignore[reportConstantRedefinition]
      
  
---|---  
  
© Pydantic Services Inc. 2024 to present

