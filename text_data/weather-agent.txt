Skip to content

[ ![logo](../../img/logo-white.svg) ](../.. "PydanticAI")

PydanticAI

Weather agent

Type to start searching

[ pydantic/pydantic-ai

  * v0.0.50
  * 8k
  * 687

](https://github.com/pydantic/pydantic-ai "Go to repository")

[ ![logo](../../img/logo-white.svg) ](../.. "PydanticAI") PydanticAI

[ pydantic/pydantic-ai

  * v0.0.50
  * 8k
  * 687

](https://github.com/pydantic/pydantic-ai "Go to repository")

  * [ Introduction  ](../..)
  * [ Installation  ](../../install/)
  * [ Getting Help  ](../../help/)
  * [ Contributing  ](../../contributing/)
  * [ Troubleshooting  ](../../troubleshooting/)
  * Documentation  Documentation 
    * [ Agents  ](../../agents/)
    * [ Models  ](../../models/)
    * [ Dependencies  ](../../dependencies/)
    * [ Function Tools  ](../../tools/)
    * [ Common Tools  ](../../common-tools/)
    * [ Results  ](../../results/)
    * [ Messages and chat history  ](../../message-history/)
    * [ Unit testing  ](../../testing/)
    * [ Debugging and Monitoring  ](../../logfire/)
    * [ Multi-agent Applications  ](../../multi-agent-applications/)
    * [ Graphs  ](../../graph/)
    * [ Evals  ](../../evals/)
    * [ Image, Audio & Document Input  ](../../input/)
    * [ MCP  ](../../mcp/)

MCP

      * [ Client  ](../../mcp/client/)
      * [ Server  ](../../mcp/server/)
      * [ MCP Run Python  ](../../mcp/run-python/)
    * [ Command Line Interface (CLI)  ](../../cli/)
  * [ Examples  ](../)

Examples

    * [ Pydantic Model  ](../pydantic-model/)
    * Weather agent  [ Weather agent  ](./) Table of contents 
      * Running the Example 
      * Example Code 
      * Running the UI 
      * UI Code 
    * [ Bank support  ](../bank-support/)
    * [ SQL Generation  ](../sql-gen/)
    * [ Flight booking  ](../flight-booking/)
    * [ RAG  ](../rag/)
    * [ Stream markdown  ](../stream-markdown/)
    * [ Stream whales  ](../stream-whales/)
    * [ Chat App with FastAPI  ](../chat-app/)
    * [ Question Graph  ](../question-graph/)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](../../api/agent/)
    * [ pydantic_ai.tools  ](../../api/tools/)
    * [ pydantic_ai.common_tools  ](../../api/common_tools/)
    * [ pydantic_ai.result  ](../../api/result/)
    * [ pydantic_ai.messages  ](../../api/messages/)
    * [ pydantic_ai.exceptions  ](../../api/exceptions/)
    * [ pydantic_ai.settings  ](../../api/settings/)
    * [ pydantic_ai.usage  ](../../api/usage/)
    * [ pydantic_ai.mcp  ](../../api/mcp/)
    * [ pydantic_ai.format_as_xml  ](../../api/format_as_xml/)
    * [ pydantic_ai.models  ](../../api/models/base/)
    * [ pydantic_ai.models.openai  ](../../api/models/openai/)
    * [ pydantic_ai.models.anthropic  ](../../api/models/anthropic/)
    * [ pydantic_ai.models.bedrock  ](../../api/models/bedrock/)
    * [ pydantic_ai.models.cohere  ](../../api/models/cohere/)
    * [ pydantic_ai.models.gemini  ](../../api/models/gemini/)
    * [ pydantic_ai.models.groq  ](../../api/models/groq/)
    * [ pydantic_ai.models.instrumented  ](../../api/models/instrumented/)
    * [ pydantic_ai.models.mistral  ](../../api/models/mistral/)
    * [ pydantic_ai.models.test  ](../../api/models/test/)
    * [ pydantic_ai.models.function  ](../../api/models/function/)
    * [ pydantic_ai.models.fallback  ](../../api/models/fallback/)
    * [ pydantic_ai.models.wrapper  ](../../api/models/wrapper/)
    * [ pydantic_ai.providers  ](../../api/providers/)
    * [ pydantic_graph  ](../../api/pydantic_graph/graph/)
    * [ pydantic_graph.nodes  ](../../api/pydantic_graph/nodes/)
    * [ pydantic_graph.persistence  ](../../api/pydantic_graph/persistence/)
    * [ pydantic_graph.mermaid  ](../../api/pydantic_graph/mermaid/)
    * [ pydantic_graph.exceptions  ](../../api/pydantic_graph/exceptions/)
    * [ pydantic_evals.dataset  ](../../api/pydantic_evals/dataset/)
    * [ pydantic_evals.evaluators  ](../../api/pydantic_evals/evaluators/)
    * [ pydantic_evals.reporting  ](../../api/pydantic_evals/reporting/)
    * [ pydantic_evals.otel  ](../../api/pydantic_evals/otel/)
    * [ pydantic_evals.generation  ](../../api/pydantic_evals/generation/)

Table of contents

  * Running the Example 
  * Example Code 
  * Running the UI 
  * UI Code 

# Weather agent

Example of PydanticAI with multiple tools which the LLM needs to call in turn
to answer a question.

Demonstrates:

  * [tools](../../tools/)
  * [agent dependencies](../../dependencies/)
  * [streaming text responses](../../results/#streaming-text)
  * Building a [Gradio](https://www.gradio.app/) UI for the agent

In this case the idea is a "weather" agent — the user can ask for the weather
in multiple locations, the agent will use the `get_lat_lng` tool to get the
latitude and longitude of the locations, then use the `get_weather` tool to
get the weather for those locations.

## Running the Example

To run this example properly, you might want to add two extra API keys **(Note
if either key is missing, the code will fall back to dummy data, so they're
not required)** :

  * A weather API key from [tomorrow.io](https://www.tomorrow.io/weather-api/) set via `WEATHER_API_KEY`
  * A geocoding API key from [geocode.maps.co](https://geocode.maps.co/) set via `GEO_API_KEY`

With [dependencies installed and environment variables set](../#usage), run:

pipuv

    
    
    python -m pydantic_ai_examples.weather_agent
    
    
    
    uv run -m pydantic_ai_examples.weather_agent
    

## Example Code

pydantic_ai_examples/weather_agent.py

    
    
    from __future__ import annotations as _annotations
    
    import asyncio
    import os
    from dataclasses import dataclass
    from typing import Any
    
    import logfire
    from devtools import debug
    from httpx import AsyncClient
    
    from pydantic_ai import Agent, ModelRetry, RunContext
    
    # 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
    logfire.configure(send_to_logfire='if-token-present')
    
    
    @dataclass
    class Deps:
        client: AsyncClient
        weather_api_key: str | None
        geo_api_key: str | None
    
    
    weather_agent = Agent(
        'openai:gpt-4o',
        # 'Be concise, reply with one sentence.' is enough for some models (like openai) to use
        # the below tools appropriately, but others like anthropic and gemini require a bit more direction.
        system_prompt=(
            'Be concise, reply with one sentence.'
            'Use the `get_lat_lng` tool to get the latitude and longitude of the locations, '
            'then use the `get_weather` tool to get the weather.'
        ),
        deps_type=Deps,
        retries=2,
        instrument=True,
    )
    
    
    @weather_agent.tool
    async def get_lat_lng(
        ctx: RunContext[Deps], location_description: str
    ) -> dict[str, float]:
        """Get the latitude and longitude of a location.
    
        Args:
            ctx: The context.
            location_description: A description of a location.
        """
        if ctx.deps.geo_api_key is None:
            # if no API key is provided, return a dummy response (London)
            return {'lat': 51.1, 'lng': -0.1}
    
        params = {
            'q': location_description,
            'api_key': ctx.deps.geo_api_key,
        }
        with logfire.span('calling geocode API', params=params) as span:
            r = await ctx.deps.client.get('https://geocode.maps.co/search', params=params)
            r.raise_for_status()
            data = r.json()
            span.set_attribute('response', data)
    
        if data:
            return {'lat': data[0]['lat'], 'lng': data[0]['lon']}
        else:
            raise ModelRetry('Could not find the location')
    
    
    @weather_agent.tool
    async def get_weather(ctx: RunContext[Deps], lat: float, lng: float) -> dict[str, Any]:
        """Get the weather at a location.
    
        Args:
            ctx: The context.
            lat: Latitude of the location.
            lng: Longitude of the location.
        """
        if ctx.deps.weather_api_key is None:
            # if no API key is provided, return a dummy response
            return {'temperature': '21 °C', 'description': 'Sunny'}
    
        params = {
            'apikey': ctx.deps.weather_api_key,
            'location': f'{lat},{lng}',
            'units': 'metric',
        }
        with logfire.span('calling weather API', params=params) as span:
            r = await ctx.deps.client.get(
                'https://api.tomorrow.io/v4/weather/realtime', params=params
            )
            r.raise_for_status()
            data = r.json()
            span.set_attribute('response', data)
    
        values = data['data']['values']
        # https://docs.tomorrow.io/reference/data-layers-weather-codes
        code_lookup = {
            1000: 'Clear, Sunny',
            1100: 'Mostly Clear',
            1101: 'Partly Cloudy',
            1102: 'Mostly Cloudy',
            1001: 'Cloudy',
            2000: 'Fog',
            2100: 'Light Fog',
            4000: 'Drizzle',
            4001: 'Rain',
            4200: 'Light Rain',
            4201: 'Heavy Rain',
            5000: 'Snow',
            5001: 'Flurries',
            5100: 'Light Snow',
            5101: 'Heavy Snow',
            6000: 'Freezing Drizzle',
            6001: 'Freezing Rain',
            6200: 'Light Freezing Rain',
            6201: 'Heavy Freezing Rain',
            7000: 'Ice Pellets',
            7101: 'Heavy Ice Pellets',
            7102: 'Light Ice Pellets',
            8000: 'Thunderstorm',
        }
        return {
            'temperature': f'{values["temperatureApparent"]:0.0f}°C',
            'description': code_lookup.get(values['weatherCode'], 'Unknown'),
        }
    
    
    async def main():
        async with AsyncClient() as client:
            # create a free API key at https://www.tomorrow.io/weather-api/
            weather_api_key = os.getenv('WEATHER_API_KEY')
            # create a free API key at https://geocode.maps.co/
            geo_api_key = os.getenv('GEO_API_KEY')
            deps = Deps(
                client=client, weather_api_key=weather_api_key, geo_api_key=geo_api_key
            )
            result = await weather_agent.run(
                'What is the weather like in London and in Wiltshire?', deps=deps
            )
            debug(result)
            print('Response:', result.data)
    
    
    if __name__ == '__main__':
        asyncio.run(main())
    

## Running the UI

You can build multi-turn chat applications for your agent with
[Gradio](https://www.gradio.app/), a framework for building AI web
applications entirely in python. Gradio comes with built-in chat components
and agent support so the entire UI will be implemented in a single python
file!

Here's what the UI looks like for the weather agent:

Note, to run the UI, you'll need Python 3.10+.

    
    
    pip install gradio>=5.9.0
    python/uv-run -m pydantic_ai_examples.weather_agent_gradio
    

## UI Code

pydantic_ai_examples/weather_agent_gradio.py

    
    
    from __future__ import annotations as _annotations
    
    import json
    import os
    
    from httpx import AsyncClient
    
    from pydantic_ai.messages import ToolCallPart, ToolReturnPart
    from pydantic_ai_examples.weather_agent import Deps, weather_agent
    
    try:
        import gradio as gr
    except ImportError as e:
        raise ImportError(
            'Please install gradio with `pip install gradio`. You must use python>=3.10.'
        ) from e
    
    TOOL_TO_DISPLAY_NAME = {'get_lat_lng': 'Geocoding API', 'get_weather': 'Weather API'}
    
    client = AsyncClient()
    weather_api_key = os.getenv('WEATHER_API_KEY')
    # create a free API key at https://geocode.maps.co/
    geo_api_key = os.getenv('GEO_API_KEY')
    deps = Deps(client=client, weather_api_key=weather_api_key, geo_api_key=geo_api_key)
    
    
    async def stream_from_agent(prompt: str, chatbot: list[dict], past_messages: list):
        chatbot.append({'role': 'user', 'content': prompt})
        yield gr.Textbox(interactive=False, value=''), chatbot, gr.skip()
        async with weather_agent.run_stream(
            prompt, deps=deps, message_history=past_messages
        ) as result:
            for message in result.new_messages():
                for call in message.parts:
                    if isinstance(call, ToolCallPart):
                        call_args = (
                            call.args.args_json
                            if hasattr(call.args, 'args_json')
                            else json.dumps(call.args.args_dict)
                        )
                        metadata = {
                            'title': f'🛠️ Using {TOOL_TO_DISPLAY_NAME[call.tool_name]}',
                        }
                        if call.tool_call_id is not None:
                            metadata['id'] = {call.tool_call_id}
    
                        gr_message = {
                            'role': 'assistant',
                            'content': 'Parameters: ' + call_args,
                            'metadata': metadata,
                        }
                        chatbot.append(gr_message)
                    if isinstance(call, ToolReturnPart):
                        for gr_message in chatbot:
                            if (
                                gr_message.get('metadata', {}).get('id', '')
                                == call.tool_call_id
                            ):
                                gr_message['content'] += (
                                    f'\nOutput: {json.dumps(call.content)}'
                                )
                    yield gr.skip(), chatbot, gr.skip()
            chatbot.append({'role': 'assistant', 'content': ''})
            async for message in result.stream_text():
                chatbot[-1]['content'] = message
                yield gr.skip(), chatbot, gr.skip()
            past_messages = result.all_messages()
    
            yield gr.Textbox(interactive=True), gr.skip(), past_messages
    
    
    async def handle_retry(chatbot, past_messages: list, retry_data: gr.RetryData):
        new_history = chatbot[: retry_data.index]
        previous_prompt = chatbot[retry_data.index]['content']
        past_messages = past_messages[: retry_data.index]
        async for update in stream_from_agent(previous_prompt, new_history, past_messages):
            yield update
    
    
    def undo(chatbot, past_messages: list, undo_data: gr.UndoData):
        new_history = chatbot[: undo_data.index]
        past_messages = past_messages[: undo_data.index]
        return chatbot[undo_data.index]['content'], new_history, past_messages
    
    
    def select_data(message: gr.SelectData) -> str:
        return message.value['text']
    
    
    with gr.Blocks() as demo:
        gr.HTML(
            """
    <div style="display: flex; justify-content: center; align-items: center; gap: 2rem; padding: 1rem; width: 100%">
        <img src="https://ai.pydantic.dev/img/logo-white.svg" style="max-width: 200px; height: auto">
        <div>
            <h1 style="margin: 0 0 1rem 0">Weather Assistant</h1>
            <h3 style="margin: 0 0 0.5rem 0">
                This assistant answer your weather questions.
            </h3>
        </div>
    </div>
    """
        )
        past_messages = gr.State([])
        chatbot = gr.Chatbot(
            label='Packing Assistant',
            type='messages',
            avatar_images=(None, 'https://ai.pydantic.dev/img/logo-white.svg'),
            examples=[
                {'text': 'What is the weather like in Miami?'},
                {'text': 'What is the weather like in London?'},
            ],
        )
        with gr.Row():
            prompt = gr.Textbox(
                lines=1,
                show_label=False,
                placeholder='What is the weather like in New York City?',
            )
        generation = prompt.submit(
            stream_from_agent,
            inputs=[prompt, chatbot, past_messages],
            outputs=[prompt, chatbot, past_messages],
        )
        chatbot.example_select(select_data, None, [prompt])
        chatbot.retry(
            handle_retry, [chatbot, past_messages], [prompt, chatbot, past_messages]
        )
        chatbot.undo(undo, [chatbot, past_messages], [prompt, chatbot, past_messages])
    
    
    if __name__ == '__main__':
        demo.launch()
    

© Pydantic Services Inc. 2024 to present

