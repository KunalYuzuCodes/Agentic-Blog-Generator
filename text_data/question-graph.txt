Skip to content

[ ![logo](../../img/logo-white.svg) ](../.. "PydanticAI")

PydanticAI

Question Graph

Type to start searching

[ pydantic/pydantic-ai

  * v0.0.50
  * 8k
  * 687

](https://github.com/pydantic/pydantic-ai "Go to repository")

[ ![logo](../../img/logo-white.svg) ](../.. "PydanticAI") PydanticAI

[ pydantic/pydantic-ai

  * v0.0.50
  * 8k
  * 687

](https://github.com/pydantic/pydantic-ai "Go to repository")

  * [ Introduction  ](../..)
  * [ Installation  ](../../install/)
  * [ Getting Help  ](../../help/)
  * [ Contributing  ](../../contributing/)
  * [ Troubleshooting  ](../../troubleshooting/)
  * Documentation  Documentation 
    * [ Agents  ](../../agents/)
    * [ Models  ](../../models/)
    * [ Dependencies  ](../../dependencies/)
    * [ Function Tools  ](../../tools/)
    * [ Common Tools  ](../../common-tools/)
    * [ Results  ](../../results/)
    * [ Messages and chat history  ](../../message-history/)
    * [ Unit testing  ](../../testing/)
    * [ Debugging and Monitoring  ](../../logfire/)
    * [ Multi-agent Applications  ](../../multi-agent-applications/)
    * [ Graphs  ](../../graph/)
    * [ Evals  ](../../evals/)
    * [ Image, Audio & Document Input  ](../../input/)
    * [ MCP  ](../../mcp/)

MCP

      * [ Client  ](../../mcp/client/)
      * [ Server  ](../../mcp/server/)
      * [ MCP Run Python  ](../../mcp/run-python/)
    * [ Command Line Interface (CLI)  ](../../cli/)
  * [ Examples  ](../)

Examples

    * [ Pydantic Model  ](../pydantic-model/)
    * [ Weather agent  ](../weather-agent/)
    * [ Bank support  ](../bank-support/)
    * [ SQL Generation  ](../sql-gen/)
    * [ Flight booking  ](../flight-booking/)
    * [ RAG  ](../rag/)
    * [ Stream markdown  ](../stream-markdown/)
    * [ Stream whales  ](../stream-whales/)
    * [ Chat App with FastAPI  ](../chat-app/)
    * Question Graph  [ Question Graph  ](./) Table of contents 
      * Running the Example 
      * Example Code 
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](../../api/agent/)
    * [ pydantic_ai.tools  ](../../api/tools/)
    * [ pydantic_ai.common_tools  ](../../api/common_tools/)
    * [ pydantic_ai.result  ](../../api/result/)
    * [ pydantic_ai.messages  ](../../api/messages/)
    * [ pydantic_ai.exceptions  ](../../api/exceptions/)
    * [ pydantic_ai.settings  ](../../api/settings/)
    * [ pydantic_ai.usage  ](../../api/usage/)
    * [ pydantic_ai.mcp  ](../../api/mcp/)
    * [ pydantic_ai.format_as_xml  ](../../api/format_as_xml/)
    * [ pydantic_ai.models  ](../../api/models/base/)
    * [ pydantic_ai.models.openai  ](../../api/models/openai/)
    * [ pydantic_ai.models.anthropic  ](../../api/models/anthropic/)
    * [ pydantic_ai.models.bedrock  ](../../api/models/bedrock/)
    * [ pydantic_ai.models.cohere  ](../../api/models/cohere/)
    * [ pydantic_ai.models.gemini  ](../../api/models/gemini/)
    * [ pydantic_ai.models.groq  ](../../api/models/groq/)
    * [ pydantic_ai.models.instrumented  ](../../api/models/instrumented/)
    * [ pydantic_ai.models.mistral  ](../../api/models/mistral/)
    * [ pydantic_ai.models.test  ](../../api/models/test/)
    * [ pydantic_ai.models.function  ](../../api/models/function/)
    * [ pydantic_ai.models.fallback  ](../../api/models/fallback/)
    * [ pydantic_ai.models.wrapper  ](../../api/models/wrapper/)
    * [ pydantic_ai.providers  ](../../api/providers/)
    * [ pydantic_graph  ](../../api/pydantic_graph/graph/)
    * [ pydantic_graph.nodes  ](../../api/pydantic_graph/nodes/)
    * [ pydantic_graph.persistence  ](../../api/pydantic_graph/persistence/)
    * [ pydantic_graph.mermaid  ](../../api/pydantic_graph/mermaid/)
    * [ pydantic_graph.exceptions  ](../../api/pydantic_graph/exceptions/)
    * [ pydantic_evals.dataset  ](../../api/pydantic_evals/dataset/)
    * [ pydantic_evals.evaluators  ](../../api/pydantic_evals/evaluators/)
    * [ pydantic_evals.reporting  ](../../api/pydantic_evals/reporting/)
    * [ pydantic_evals.otel  ](../../api/pydantic_evals/otel/)
    * [ pydantic_evals.generation  ](../../api/pydantic_evals/generation/)

Table of contents

  * Running the Example 
  * Example Code 

# Question Graph

Example of a graph for asking and evaluating questions.

Demonstrates:

  * [`pydantic_graph`](../../graph/)

## Running the Example

With [dependencies installed and environment variables set](../#usage), run:

pipuv

    
    
    python -m pydantic_ai_examples.question_graph
    
    
    
    uv run -m pydantic_ai_examples.question_graph
    

## Example Code

question_graph.py

    
    
    from __future__ import annotations as _annotations
    
    from dataclasses import dataclass, field
    from pathlib import Path
    
    import logfire
    from groq import BaseModel
    from pydantic_graph import (
        BaseNode,
        End,
        Graph,
        GraphRunContext,
    )
    from pydantic_graph.persistence.file import FileStatePersistence
    
    from pydantic_ai import Agent
    from pydantic_ai.format_as_xml import format_as_xml
    from pydantic_ai.messages import ModelMessage
    
    # 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
    logfire.configure(send_to_logfire='if-token-present')
    
    ask_agent = Agent('openai:gpt-4o', result_type=str, instrument=True)
    
    
    @dataclass
    class QuestionState:
        question: str | None = None
        ask_agent_messages: list[ModelMessage] = field(default_factory=list)
        evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)
    
    
    @dataclass
    class Ask(BaseNode[QuestionState]):
        async def run(self, ctx: GraphRunContext[QuestionState]) -> Answer:
            result = await ask_agent.run(
                'Ask a simple question with a single correct answer.',
                message_history=ctx.state.ask_agent_messages,
            )
            ctx.state.ask_agent_messages += result.all_messages()
            ctx.state.question = result.data
            return Answer(result.data)
    
    
    @dataclass
    class Answer(BaseNode[QuestionState]):
        question: str
    
        async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:
            answer = input(f'{self.question}: ')
            return Evaluate(answer)
    
    
    class EvaluationResult(BaseModel, use_attribute_docstrings=True):
        correct: bool
        """Whether the answer is correct."""
        comment: str
        """Comment on the answer, reprimand the user if the answer is wrong."""
    
    
    evaluate_agent = Agent(
        'openai:gpt-4o',
        result_type=EvaluationResult,
        system_prompt='Given a question and answer, evaluate if the answer is correct.',
    )
    
    
    @dataclass
    class Evaluate(BaseNode[QuestionState, None, str]):
        answer: str
    
        async def run(
            self,
            ctx: GraphRunContext[QuestionState],
        ) -> End[str] | Reprimand:
            assert ctx.state.question is not None
            result = await evaluate_agent.run(
                format_as_xml({'question': ctx.state.question, 'answer': self.answer}),
                message_history=ctx.state.evaluate_agent_messages,
            )
            ctx.state.evaluate_agent_messages += result.all_messages()
            if result.data.correct:
                return End(result.data.comment)
            else:
                return Reprimand(result.data.comment)
    
    
    @dataclass
    class Reprimand(BaseNode[QuestionState]):
        comment: str
    
        async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:
            print(f'Comment: {self.comment}')
            ctx.state.question = None
            return Ask()
    
    
    question_graph = Graph(
        nodes=(Ask, Answer, Evaluate, Reprimand), state_type=QuestionState
    )
    
    
    async def run_as_continuous():
        state = QuestionState()
        node = Ask()
        end = await question_graph.run(node, state=state)
        print('END:', end.output)
    
    
    async def run_as_cli(answer: str | None):
        persistence = FileStatePersistence(Path('question_graph.json'))
        persistence.set_graph_types(question_graph)
    
        if snapshot := await persistence.load_next():
            state = snapshot.state
            assert answer is not None, (
                'answer required, usage "uv run -m pydantic_ai_examples.question_graph cli <answer>"'
            )
            node = Evaluate(answer)
        else:
            state = QuestionState()
            node = Ask()
        # debug(state, node)
    
        async with question_graph.iter(node, state=state, persistence=persistence) as run:
            while True:
                node = await run.next()
                if isinstance(node, End):
                    print('END:', node.data)
                    history = await persistence.load_all()
                    print('history:', '\n'.join(str(e.node) for e in history), sep='\n')
                    print('Finished!')
                    break
                elif isinstance(node, Answer):
                    print(node.question)
                    break
                # otherwise just continue
    
    
    if __name__ == '__main__':
        import asyncio
        import sys
    
        try:
            sub_command = sys.argv[1]
            assert sub_command in ('continuous', 'cli', 'mermaid')
        except (IndexError, AssertionError):
            print(
                'Usage:\n'
                '  uv run -m pydantic_ai_examples.question_graph mermaid\n'
                'or:\n'
                '  uv run -m pydantic_ai_examples.question_graph continuous\n'
                'or:\n'
                '  uv run -m pydantic_ai_examples.question_graph cli [answer]',
                file=sys.stderr,
            )
            sys.exit(1)
    
        if sub_command == 'mermaid':
            print(question_graph.mermaid_code(start_node=Ask))
        elif sub_command == 'continuous':
            asyncio.run(run_as_continuous())
        else:
            a = sys.argv[2] if len(sys.argv) > 2 else None
            asyncio.run(run_as_cli(a))
    

The mermaid diagram generated in this example looks like this:

© Pydantic Services Inc. 2024 to present

